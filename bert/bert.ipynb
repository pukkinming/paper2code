{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24bbb34-dec3-4b89-a488-359970b6da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336ff52-745f-40d8-92cf-b2893faccb1b",
   "metadata": {},
   "source": [
    "# BERT (Bidirectional Encoder Representations from Transformers)\n",
    "\n",
    "BERT is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. It is notable for its dramatic improvement over previous state-of-the-art models, and as an early example of a large language model. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments.\n",
    "\n",
    "Key hightlights for BERT include:\n",
    "- Only encoder layers are used (no decoder).\n",
    "- For pretraining tasks, we have\n",
    "  - Masked Language Modeling (MLM) – Predict masked tokens.\n",
    "  - Next Sentence Prediction (NSP) – Classify whether two sentences follow each other.\n",
    "\n",
    "The key innovation is its truly bidirectional nature, allowing it to consider context from both directions simultaneously during pre-training.\n",
    "\n",
    "## Model Variants\n",
    "\n",
    "- BERT-Base: 12 transformer layers, 12 attention heads, 768 hidden dimensions (110M parameters)\n",
    "- BERT-Large: 24 transformer layers, 16 attention heads, 1024 hidden dimensions (340M parameters)\n",
    "\n",
    "\n",
    "\n",
    "## Model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4b2653-bd61-410f-a973-cc420be56643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = 10000 ** (-torch.arange(0, d_model, 2, dtype=torch.float) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)  # No addition here!\n",
    "\n",
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.shape[0]\n",
    "\n",
    "        # batch, seq_len, d_model -> batch, seq_len, num_heads, d_k\n",
    "        q = self.w_q(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.w_k(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.w_v(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.d_k ** 0.5)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2)  # Change shape to (batch_size, 1, 1, seq_len)\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        output = torch.matmul(attn, v).transpose(1, 2).contiguous().view(batch_size, -1, self.d_k * self.num_heads)\n",
    "        return self.fc(output)\n",
    "\n",
    "\n",
    "# Feed Forward Layer\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "\n",
    "# Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out = self.attention(x, x, x, mask)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        return self.norm2(x + ff_out)\n",
    "\n",
    "\n",
    "# BERT Model\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, num_heads=4, num_layers=2, d_ff=256, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.segment_embedding = nn.Embedding(2, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.mlm_head = nn.Linear(d_model, vocab_size)\n",
    "        self.nsp_head = nn.Linear(d_model, 2)\n",
    "\n",
    "    def forward(self, x, segment_ids, attention_mask):\n",
    "        x = self.word_embedding(x) + self.segment_embedding(segment_ids)\n",
    "        x = self.pos_encoding(x)\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, attention_mask)\n",
    "        x = self.norm(x)\n",
    "        cls_token_output = x[:, 0, :]\n",
    "        return self.mlm_head(x), self.nsp_head(cls_token_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc18f581-cb47-4375-a170-6f42e9c8ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 131.169074M\n"
     ]
    }
   ],
   "source": [
    "base_bert_model = BERTModel(vocab_size=30000, d_model=768, num_heads=12, num_layers=12, d_ff=3072)\n",
    "total_params = sum(p.numel() for p in base_bert_model.parameters())\n",
    "print(f\"Number of parameters: {total_params/1000000}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb518f5-f2ef-40a7-948e-333718a69f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 363.785522M\n"
     ]
    }
   ],
   "source": [
    "large_bert_model = BERTModel(vocab_size=30000, d_model=1024, num_heads=16, num_layers=24, d_ff=4096)\n",
    "\n",
    "total_params = sum(p.numel() for p in large_bert_model.parameters())\n",
    "print(f\"Number of parameters: {total_params/1000000}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1086673-cec4-44d7-8e6f-c0efc7bea007",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bbc7e8e-a33d-433f-b0a9-c7dfb77164ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pretrain_data(sentence_pairs, tokenizer, seq_len=32, mask_prob=0.15):\n",
    "    input_ids, segment_ids, attention_masks, mlm_labels, nsp_labels = [], [], [], [], []\n",
    "\n",
    "    for pair in sentence_pairs:\n",
    "        sentence1 = tokenizer.encode(pair[\"sentence1\"], add_special_tokens=False)\n",
    "        sentence2 = tokenizer.encode(pair[\"sentence2\"], add_special_tokens=False)\n",
    "\n",
    "        # Add [CLS] and [SEP] tokens\n",
    "        tokens = [101] + sentence1 + [102] + sentence2 + [102]\n",
    "        segment_id = [0] * (len(sentence1) + 2) + [1] * (len(sentence2) + 1)\n",
    "\n",
    "        # Pad sequences to fixed length\n",
    "        padding_length = seq_len - len(tokens)\n",
    "        tokens += [0] * padding_length\n",
    "        segment_id += [0] * padding_length\n",
    "\n",
    "        # Prepare MLM labels (default -100 means no prediction)\n",
    "        mlm_labels_example = [-100] * seq_len  \n",
    "\n",
    "        # Refer to section 3.1 of the paper - Pre-training BERT for masking details\n",
    "        # Select 15% of tokens to be masked\n",
    "        candidate_indexes = [i for i in range(1, len(tokens) - 1) if tokens[i] != 0]  # Exclude CLS and SEP\n",
    "        num_to_mask = max(1, int(len(candidate_indexes) * mask_prob))\n",
    "        mask_indexes = random.sample(candidate_indexes, num_to_mask)\n",
    "\n",
    "        for idx in mask_indexes:\n",
    "            prob = random.random()\n",
    "\n",
    "            if prob < 0.8:  # 80% replace with [MASK]\n",
    "                mlm_labels_example[idx] = tokens[idx]\n",
    "                tokens[idx] = 103  # [MASK] token\n",
    "            elif prob < 0.9:  # 10% replace with a random token\n",
    "                mlm_labels_example[idx] = tokens[idx]\n",
    "                tokens[idx] = random.randint(1, tokenizer.vocab_size - 1)\n",
    "            else:  # 10% keep unchanged\n",
    "                mlm_labels_example[idx] = tokens[idx]\n",
    "\n",
    "        # Prepare attention mask\n",
    "        attention_mask = [1 if token != 0 else 0 for token in tokens]\n",
    "\n",
    "        # Append processed data\n",
    "        input_ids.append(torch.tensor(tokens))\n",
    "        segment_ids.append(torch.tensor(segment_id))\n",
    "        attention_masks.append(torch.tensor(attention_mask))\n",
    "        mlm_labels.append(torch.tensor(mlm_labels_example))\n",
    "        nsp_labels.append(torch.tensor(pair[\"is_next\"]))\n",
    "\n",
    "    return {\n",
    "        'input_ids': torch.stack(input_ids),\n",
    "        'segment_ids': torch.stack(segment_ids),\n",
    "        'attention_masks': torch.stack(attention_masks),\n",
    "        'mlm_labels': torch.stack(mlm_labels),\n",
    "        'nsp_labels': torch.tensor(nsp_labels)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc64089-a67e-4f94-ac27-3134e9c0b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_bert(model, dataloader, optimizer, criterion_mlm, criterion_nsp, epochs=5):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            input_ids, segment_ids, attention_masks, mlm_labels, nsp_labels = [b.to(device) for b in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            mlm_outputs, nsp_outputs = model(input_ids, segment_ids, attention_masks)\n",
    "\n",
    "            # Compute loss\n",
    "            mlm_loss = criterion_mlm(mlm_outputs.view(-1, tokenizer.vocab_size), mlm_labels.view(-1))\n",
    "            nsp_loss = criterion_nsp(nsp_outputs, nsp_labels)\n",
    "\n",
    "            loss = mlm_loss + nsp_loss  # Combined loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c00dae-146e-47f8-aeab-a45c740f72fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 10.8917\n",
      "Epoch [2/30], Loss: 10.7370\n",
      "Epoch [3/30], Loss: 10.6251\n",
      "Epoch [4/30], Loss: 10.4796\n",
      "Epoch [5/30], Loss: 10.3927\n",
      "Epoch [6/30], Loss: 10.2092\n",
      "Epoch [7/30], Loss: 10.1402\n",
      "Epoch [8/30], Loss: 9.9670\n",
      "Epoch [9/30], Loss: 9.9057\n",
      "Epoch [10/30], Loss: 9.7889\n",
      "Epoch [11/30], Loss: 9.7430\n",
      "Epoch [12/30], Loss: 9.5793\n",
      "Epoch [13/30], Loss: 9.4266\n",
      "Epoch [14/30], Loss: 9.3539\n",
      "Epoch [15/30], Loss: 9.2606\n",
      "Epoch [16/30], Loss: 9.1283\n",
      "Epoch [17/30], Loss: 9.0709\n",
      "Epoch [18/30], Loss: 9.0162\n",
      "Epoch [19/30], Loss: 8.8572\n",
      "Epoch [20/30], Loss: 8.7454\n",
      "Epoch [21/30], Loss: 8.6200\n",
      "Epoch [22/30], Loss: 8.6164\n",
      "Epoch [23/30], Loss: 8.4726\n",
      "Epoch [24/30], Loss: 8.4096\n",
      "Epoch [25/30], Loss: 8.2672\n",
      "Epoch [26/30], Loss: 8.2396\n",
      "Epoch [27/30], Loss: 8.1575\n",
      "Epoch [28/30], Loss: 8.0223\n",
      "Epoch [29/30], Loss: 7.9591\n",
      "Epoch [30/30], Loss: 7.9420\n"
     ]
    }
   ],
   "source": [
    "# Define sentence pairs\n",
    "sentence_pairs = [\n",
    "    {\"sentence1\": \"The weather is nice today.\", \"sentence2\": \"Let's go for a walk.\", \"is_next\": 1},\n",
    "    {\"sentence1\": \"He went to the market.\", \"sentence2\": \"The sky looks cloudy.\", \"is_next\": 0},\n",
    "    {\"sentence1\": \"I enjoy reading books.\", \"sentence2\": \"I love science fiction.\", \"is_next\": 1},\n",
    "    {\"sentence1\": \"She prepared a delicious meal.\", \"sentence2\": \"The guests were impressed.\", \"is_next\": 1},\n",
    "    {\"sentence1\": \"He studies very hard.\", \"sentence2\": \"The exams are approaching.\", \"is_next\": 1},\n",
    "    {\"sentence1\": \"My dog is very playful.\", \"sentence2\": \"I need to buy some groceries.\", \"is_next\": 0},\n",
    "    {\"sentence1\": \"The concert was amazing.\", \"sentence2\": \"We had a great time.\", \"is_next\": 1},\n",
    "    {\"sentence1\": \"The coffee machine is broken.\", \"sentence2\": \"I need to call a technician.\", \"is_next\": 1},\n",
    "    {\"sentence1\": \"The restaurant is famous.\", \"sentence2\": \"The service was terrible.\", \"is_next\": 0},\n",
    "    {\"sentence1\": \"He likes to play soccer.\", \"sentence2\": \"His team won the championship.\", \"is_next\": 1},\n",
    "]\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pretraining data\n",
    "pretrain_data = prepare_pretrain_data(sentence_pairs, tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 2\n",
    "pretrain_dataset = TensorDataset(pretrain_data[\"input_ids\"], pretrain_data[\"segment_ids\"],\n",
    "                                 pretrain_data[\"attention_masks\"], pretrain_data[\"mlm_labels\"],\n",
    "                                 pretrain_data[\"nsp_labels\"])\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# Initialize model and optimizer\n",
    "bert_model = BERTModel(vocab_size).to(device)\n",
    "optimizer = optim.Adam(bert_model.parameters(), lr=5e-5)\n",
    "criterion_mlm = nn.CrossEntropyLoss(ignore_index=-100)  # Ignore padding for MLM\n",
    "criterion_nsp = nn.CrossEntropyLoss()\n",
    "\n",
    "# Start pretraining\n",
    "pretrained_bert_model = pretrain_bert(bert_model, pretrain_loader, optimizer, criterion_mlm, criterion_nsp, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6e6f4-6f2c-4cda-97aa-a712b1a7e312",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e91ddf-914a-43c8-9270-0ea73d51fa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTModel(\n",
       "  (word_embedding): Embedding(30522, 128)\n",
       "  (segment_embedding): Embedding(2, 128)\n",
       "  (pos_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-1): 2 x EncoderLayer(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlm_head): Linear(in_features=128, out_features=30522, bias=True)\n",
       "  (nsp_head): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_bert_model.nsp_head = nn.Linear(128, 2)\n",
    "pretrained_bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43433e9-27cd-48f0-a4be-1ddcf586d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare fine-tuning data\n",
    "fine_tune_data = [\n",
    "    {\"text\": \"I love this movie!\", \"label\": 1,},\n",
    "    {\"text\": \"This product is terrible.\", \"label\": 0,},\n",
    "    {\"text\": \"The food was fantastic.\", \"label\": 1,},\n",
    "    {\"text\": \"It was a boring experience.\", \"label\": 0,},\n",
    "]\n",
    "\n",
    "# Prepare fine-tuning dataset\n",
    "def prepare_finetune_data(fine_tune_data, tokenizer, seq_len=32):\n",
    "    input_ids, attention_masks, segments, labels = [], [], [], []\n",
    "    for item in fine_tune_data:\n",
    "        tokens = tokenizer.encode(item[\"text\"], max_length=seq_len, padding=\"max_length\", truncation=True)\n",
    "        input_ids.append(torch.tensor(tokens))\n",
    "        attention_masks.append(torch.tensor([1 if token != 0 else 0 for token in tokens]))\n",
    "        segments.append(torch.tensor([0 for _ in range(seq_len)]))\n",
    "        labels.append(torch.tensor(item[\"label\"]))\n",
    "    return {\n",
    "        'input_ids': torch.stack(input_ids),\n",
    "        'attention_masks': torch.stack(attention_masks),\n",
    "        'segments': torch.stack(segments), \n",
    "        'labels': torch.tensor(labels)\n",
    "    }\n",
    "\n",
    "def finetune_model(model, dataloader, optimizer, criterion, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_masks, segments, labels = [b.to(device) for b in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            _, logits = model(input_ids, segments, attention_masks)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355cf8d5-88b5-44f9-8841-168caaa60d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6980\n",
      "Epoch [2/200], Loss: 0.6943\n",
      "Epoch [3/200], Loss: 0.6911\n",
      "Epoch [4/200], Loss: 0.6882\n",
      "Epoch [5/200], Loss: 0.6856\n",
      "Epoch [6/200], Loss: 0.6831\n",
      "Epoch [7/200], Loss: 0.6807\n",
      "Epoch [8/200], Loss: 0.6784\n",
      "Epoch [9/200], Loss: 0.6760\n",
      "Epoch [10/200], Loss: 0.6736\n",
      "Epoch [11/200], Loss: 0.6711\n",
      "Epoch [12/200], Loss: 0.6685\n",
      "Epoch [13/200], Loss: 0.6660\n",
      "Epoch [14/200], Loss: 0.6634\n",
      "Epoch [15/200], Loss: 0.6609\n",
      "Epoch [16/200], Loss: 0.6584\n",
      "Epoch [17/200], Loss: 0.6559\n",
      "Epoch [18/200], Loss: 0.6533\n",
      "Epoch [19/200], Loss: 0.6508\n",
      "Epoch [20/200], Loss: 0.6482\n",
      "Epoch [21/200], Loss: 0.6456\n",
      "Epoch [22/200], Loss: 0.6429\n",
      "Epoch [23/200], Loss: 0.6402\n",
      "Epoch [24/200], Loss: 0.6374\n",
      "Epoch [25/200], Loss: 0.6346\n",
      "Epoch [26/200], Loss: 0.6318\n",
      "Epoch [27/200], Loss: 0.6289\n",
      "Epoch [28/200], Loss: 0.6260\n",
      "Epoch [29/200], Loss: 0.6231\n",
      "Epoch [30/200], Loss: 0.6201\n",
      "Epoch [31/200], Loss: 0.6171\n",
      "Epoch [32/200], Loss: 0.6141\n",
      "Epoch [33/200], Loss: 0.6109\n",
      "Epoch [34/200], Loss: 0.6078\n",
      "Epoch [35/200], Loss: 0.6046\n",
      "Epoch [36/200], Loss: 0.6013\n",
      "Epoch [37/200], Loss: 0.5980\n",
      "Epoch [38/200], Loss: 0.5946\n",
      "Epoch [39/200], Loss: 0.5911\n",
      "Epoch [40/200], Loss: 0.5876\n",
      "Epoch [41/200], Loss: 0.5840\n",
      "Epoch [42/200], Loss: 0.5804\n",
      "Epoch [43/200], Loss: 0.5766\n",
      "Epoch [44/200], Loss: 0.5729\n",
      "Epoch [45/200], Loss: 0.5690\n",
      "Epoch [46/200], Loss: 0.5651\n",
      "Epoch [47/200], Loss: 0.5611\n",
      "Epoch [48/200], Loss: 0.5570\n",
      "Epoch [49/200], Loss: 0.5528\n",
      "Epoch [50/200], Loss: 0.5485\n",
      "Epoch [51/200], Loss: 0.5442\n",
      "Epoch [52/200], Loss: 0.5398\n",
      "Epoch [53/200], Loss: 0.5352\n",
      "Epoch [54/200], Loss: 0.5306\n",
      "Epoch [55/200], Loss: 0.5259\n",
      "Epoch [56/200], Loss: 0.5212\n",
      "Epoch [57/200], Loss: 0.5163\n",
      "Epoch [58/200], Loss: 0.5113\n",
      "Epoch [59/200], Loss: 0.5063\n",
      "Epoch [60/200], Loss: 0.5011\n",
      "Epoch [61/200], Loss: 0.4958\n",
      "Epoch [62/200], Loss: 0.4905\n",
      "Epoch [63/200], Loss: 0.4850\n",
      "Epoch [64/200], Loss: 0.4794\n",
      "Epoch [65/200], Loss: 0.4738\n",
      "Epoch [66/200], Loss: 0.4680\n",
      "Epoch [67/200], Loss: 0.4621\n",
      "Epoch [68/200], Loss: 0.4561\n",
      "Epoch [69/200], Loss: 0.4501\n",
      "Epoch [70/200], Loss: 0.4439\n",
      "Epoch [71/200], Loss: 0.4376\n",
      "Epoch [72/200], Loss: 0.4312\n",
      "Epoch [73/200], Loss: 0.4247\n",
      "Epoch [74/200], Loss: 0.4182\n",
      "Epoch [75/200], Loss: 0.4115\n",
      "Epoch [76/200], Loss: 0.4048\n",
      "Epoch [77/200], Loss: 0.3981\n",
      "Epoch [78/200], Loss: 0.3912\n",
      "Epoch [79/200], Loss: 0.3842\n",
      "Epoch [80/200], Loss: 0.3771\n",
      "Epoch [81/200], Loss: 0.3699\n",
      "Epoch [82/200], Loss: 0.3627\n",
      "Epoch [83/200], Loss: 0.3554\n",
      "Epoch [84/200], Loss: 0.3481\n",
      "Epoch [85/200], Loss: 0.3407\n",
      "Epoch [86/200], Loss: 0.3332\n",
      "Epoch [87/200], Loss: 0.3257\n",
      "Epoch [88/200], Loss: 0.3182\n",
      "Epoch [89/200], Loss: 0.3106\n",
      "Epoch [90/200], Loss: 0.3030\n",
      "Epoch [91/200], Loss: 0.2954\n",
      "Epoch [92/200], Loss: 0.2878\n",
      "Epoch [93/200], Loss: 0.2802\n",
      "Epoch [94/200], Loss: 0.2726\n",
      "Epoch [95/200], Loss: 0.2650\n",
      "Epoch [96/200], Loss: 0.2575\n",
      "Epoch [97/200], Loss: 0.2500\n",
      "Epoch [98/200], Loss: 0.2426\n",
      "Epoch [99/200], Loss: 0.2352\n",
      "Epoch [100/200], Loss: 0.2279\n",
      "Epoch [101/200], Loss: 0.2207\n",
      "Epoch [102/200], Loss: 0.2136\n",
      "Epoch [103/200], Loss: 0.2065\n",
      "Epoch [104/200], Loss: 0.1996\n",
      "Epoch [105/200], Loss: 0.1928\n",
      "Epoch [106/200], Loss: 0.1861\n",
      "Epoch [107/200], Loss: 0.1795\n",
      "Epoch [108/200], Loss: 0.1731\n",
      "Epoch [109/200], Loss: 0.1668\n",
      "Epoch [110/200], Loss: 0.1606\n",
      "Epoch [111/200], Loss: 0.1546\n",
      "Epoch [112/200], Loss: 0.1487\n",
      "Epoch [113/200], Loss: 0.1430\n",
      "Epoch [114/200], Loss: 0.1374\n",
      "Epoch [115/200], Loss: 0.1320\n",
      "Epoch [116/200], Loss: 0.1268\n",
      "Epoch [117/200], Loss: 0.1218\n",
      "Epoch [118/200], Loss: 0.1170\n",
      "Epoch [119/200], Loss: 0.1123\n",
      "Epoch [120/200], Loss: 0.1077\n",
      "Epoch [121/200], Loss: 0.1034\n",
      "Epoch [122/200], Loss: 0.0992\n",
      "Epoch [123/200], Loss: 0.0952\n",
      "Epoch [124/200], Loss: 0.0913\n",
      "Epoch [125/200], Loss: 0.0876\n",
      "Epoch [126/200], Loss: 0.0841\n",
      "Epoch [127/200], Loss: 0.0807\n",
      "Epoch [128/200], Loss: 0.0774\n",
      "Epoch [129/200], Loss: 0.0744\n",
      "Epoch [130/200], Loss: 0.0714\n",
      "Epoch [131/200], Loss: 0.0686\n",
      "Epoch [132/200], Loss: 0.0659\n",
      "Epoch [133/200], Loss: 0.0633\n",
      "Epoch [134/200], Loss: 0.0609\n",
      "Epoch [135/200], Loss: 0.0585\n",
      "Epoch [136/200], Loss: 0.0563\n",
      "Epoch [137/200], Loss: 0.0542\n",
      "Epoch [138/200], Loss: 0.0521\n",
      "Epoch [139/200], Loss: 0.0502\n",
      "Epoch [140/200], Loss: 0.0484\n",
      "Epoch [141/200], Loss: 0.0466\n",
      "Epoch [142/200], Loss: 0.0450\n",
      "Epoch [143/200], Loss: 0.0434\n",
      "Epoch [144/200], Loss: 0.0419\n",
      "Epoch [145/200], Loss: 0.0405\n",
      "Epoch [146/200], Loss: 0.0391\n",
      "Epoch [147/200], Loss: 0.0378\n",
      "Epoch [148/200], Loss: 0.0366\n",
      "Epoch [149/200], Loss: 0.0354\n",
      "Epoch [150/200], Loss: 0.0343\n",
      "Epoch [151/200], Loss: 0.0332\n",
      "Epoch [152/200], Loss: 0.0322\n",
      "Epoch [153/200], Loss: 0.0312\n",
      "Epoch [154/200], Loss: 0.0303\n",
      "Epoch [155/200], Loss: 0.0294\n",
      "Epoch [156/200], Loss: 0.0285\n",
      "Epoch [157/200], Loss: 0.0277\n",
      "Epoch [158/200], Loss: 0.0269\n",
      "Epoch [159/200], Loss: 0.0262\n",
      "Epoch [160/200], Loss: 0.0255\n",
      "Epoch [161/200], Loss: 0.0248\n",
      "Epoch [162/200], Loss: 0.0241\n",
      "Epoch [163/200], Loss: 0.0235\n",
      "Epoch [164/200], Loss: 0.0229\n",
      "Epoch [165/200], Loss: 0.0223\n",
      "Epoch [166/200], Loss: 0.0218\n",
      "Epoch [167/200], Loss: 0.0213\n",
      "Epoch [168/200], Loss: 0.0207\n",
      "Epoch [169/200], Loss: 0.0203\n",
      "Epoch [170/200], Loss: 0.0198\n",
      "Epoch [171/200], Loss: 0.0193\n",
      "Epoch [172/200], Loss: 0.0189\n",
      "Epoch [173/200], Loss: 0.0185\n",
      "Epoch [174/200], Loss: 0.0181\n",
      "Epoch [175/200], Loss: 0.0177\n",
      "Epoch [176/200], Loss: 0.0173\n",
      "Epoch [177/200], Loss: 0.0170\n",
      "Epoch [178/200], Loss: 0.0166\n",
      "Epoch [179/200], Loss: 0.0163\n",
      "Epoch [180/200], Loss: 0.0160\n",
      "Epoch [181/200], Loss: 0.0156\n",
      "Epoch [182/200], Loss: 0.0153\n",
      "Epoch [183/200], Loss: 0.0150\n",
      "Epoch [184/200], Loss: 0.0148\n",
      "Epoch [185/200], Loss: 0.0145\n",
      "Epoch [186/200], Loss: 0.0142\n",
      "Epoch [187/200], Loss: 0.0140\n",
      "Epoch [188/200], Loss: 0.0137\n",
      "Epoch [189/200], Loss: 0.0135\n",
      "Epoch [190/200], Loss: 0.0132\n",
      "Epoch [191/200], Loss: 0.0130\n",
      "Epoch [192/200], Loss: 0.0128\n",
      "Epoch [193/200], Loss: 0.0126\n",
      "Epoch [194/200], Loss: 0.0124\n",
      "Epoch [195/200], Loss: 0.0122\n",
      "Epoch [196/200], Loss: 0.0120\n",
      "Epoch [197/200], Loss: 0.0118\n",
      "Epoch [198/200], Loss: 0.0116\n",
      "Epoch [199/200], Loss: 0.0114\n",
      "Epoch [200/200], Loss: 0.0112\n"
     ]
    }
   ],
   "source": [
    "fine_tune_dataset = prepare_finetune_data(fine_tune_data, tokenizer)\n",
    "\n",
    "fine_tune_dataloader = DataLoader(\n",
    "    TensorDataset(\n",
    "        fine_tune_dataset['input_ids'],\n",
    "        fine_tune_dataset['attention_masks'],\n",
    "        fine_tune_dataset['segments'],\n",
    "        fine_tune_dataset['labels']\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(pretrained_bert_model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "finetuned_model = finetune_model(pretrained_bert_model, fine_tune_dataloader, optimizer, criterion, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d060c7-26f9-42a6-aea2-09bba5cab98e",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e11201-e226-4e4d-be4d-180c25c97efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # input_ids, attention_masks, labels = batch\n",
    "            input_ids, attention_masks, segments, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            _, logits = model(input_ids, segments, attention_masks)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    print(f\"Evaluation Results:\\nAccuracy: {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall: {rec:.4f}\\nF1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3874bb-a21b-49ae-b20d-e587fce1ea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "evaluate_data = [\n",
    "    {\"text\": \"I love this film!\", \"label\": 1,},\n",
    "    {\"text\": \"This product is bad.\", \"label\": 0,},\n",
    "    {\"text\": \"The food was excellent.\", \"label\": 1,},\n",
    "    {\"text\": \"It was a dull experience.\", \"label\": 0,},\n",
    "\n",
    "    # {\"text\": \"I love this movie!\", \"label\": 1,},\n",
    "    # {\"text\": \"This product is terrible.\", \"label\": 0,},\n",
    "    # {\"text\": \"The food was fantastic.\", \"label\": 1,},\n",
    "    # {\"text\": \"It was a boring experience.\", \"label\": 0,},\n",
    "]\n",
    "\n",
    "evaluate_dataset = prepare_finetune_data(evaluate_data, tokenizer)\n",
    "\n",
    "evaluate_dataloader = DataLoader(\n",
    "    TensorDataset(\n",
    "        evaluate_dataset['input_ids'],\n",
    "        evaluate_dataset['attention_masks'],\n",
    "        evaluate_dataset['segments'],\n",
    "        evaluate_dataset['labels']\n",
    "    ),\n",
    "    batch_size=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "evaluate_model(finetuned_model, evaluate_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf2855-0383-407a-9b23-295a4fa22164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618fc104-0979-4656-bf37-35779e55adba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_fine_tuning",
   "language": "python",
   "name": "llm_fine_tuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
